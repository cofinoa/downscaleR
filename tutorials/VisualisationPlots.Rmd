---
title: "EUPORIAS Validation Plots"
author: "Universidad de Cantabria"
date: "12/16/2014"
output:
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: 3
---

# Proposed visualizations

This document shows some sample R functions to visualize seasonal forecast information with different levels of complexity.

## Requirements

The functions have been incorporated into the development branch of downscaleR. Get the latest version using the following code. This has to be done **just once**. 

```{r eval=FALSE}
library(devtools)
devtools::install_github(c("SantanderMetGroup/downscaleR.java@master",
                           "SantanderMetGroup/downscaleR@master",
                           "SantanderMetGroup/ecomsUDG.Raccess@master"))
```

We'll need to load some packages and log into the ECOMS UDG: 

```{r message=FALSE, warning=FALSE}
library(downscaleR)
library(ecomsUDG.Raccess)
library(verification)
library(RColorBrewer)
library(scales)
library(vioplot)

loginECOMS_UDG("username", "password")
```

```{r echo=FALSE}
loginECOMS_UDG("dfrias", "friasmd")
```

## Sample data

We can load some sample data from the ECOMS-UDG. E.g. for surface temperature:

```{r}
var <- "tas"
year.ini <- 1991
year.end <- 2000
year.target <- 1998
season <- c(12,1,2)
lagged.season <- c(8,9,10,11,12,1,2)
lead.month <- 3
members <- 1:15
```

The plots shown in this document are focused on Spain:
```{r}
lonlim <- c(-10,5)
latlim <- c(35,45)
```

but you could choose any other region by setting appropriate lat-lon boundaries. For example, for Peru:

```{r eval=FALSE}
lonlim <- c(-83,-66)
latlim <- c(-20,0)
```

We are ready to load the predictions and observations. We can use downscaleR functions to interpolate the data to a common grid.

```{r cache=FALSE, message=FALSE, warning=FALSE}
prd <- loadECOMS(dataset = "System4_seasonal_15", var=var,
                 lonLim=lonlim, latLim=latlim, season=season, years=year.ini:year.end,
                 leadMonth=lead.month, members=members, time="DD"
)

obs <- loadECOMS(dataset = "WFDEI", var=var,
                 lonLim=lonlim, latLim=latlim, season=season, years=year.ini:year.end
)

obs <- interpGridData(obs, new.grid = getGrid(prd), method = "nearest")
```

## Visualization functions

### Tercile bar plot

```{r warning=FALSE}
tercileBarValidation(prd, obs, year.target)
```

### Box plots on climatology fan chart

In this plot the background represents the climatology for the forecast period. The shaded areas show the central tercile (dark shade) and the maximum and minimum (light shade). To avoid overinterpretation of daily peaks, the daily data has beed smoothed by means of a (centered) moving average of 31 days. Therefore, at the location of the boxplots, the background shows the monthly mean forecast (the terciles and extremes being computed over members and years).

The boxplots show the spread of the monthly mean forecast (for the different members).

```{r fig.height=3, warning=FALSE}
boxplotValidation(prd, obs, year.target)
```

The boxplots can be replaced by _violin plots_, to unveil multimodalities in the data.

```{r fig.height=3, warning=FALSE}
boxplotValidation(prd, obs, year.target, violin=T)
```

### Tercile plot

```{r fig.height=3.5, warning=FALSE}
tercileValidation(prd, obs)
tercileValidation(prd, obs, color.pal="rgb")
```

### Bubble plot

The bubble plot represents the most likely tercile in colors, the probability of that tercile with the size of the bubble (optional) and the skill of the forecast system for that tercile as transparency of the bubble (optional). Currently, the skill score used is the ROCSS. Only positive scores are shown (the negative ones --the system is worse than the climatology-- are shown as crosses).

```{r echo=FALSE}
index.mean <- function(X, INDEX){
  return(tapply(X, INDEX=INDEX, FUN=mean, na.rm = TRUE))
}

yearmean <- function(obj, MARGIN){
  yr <- getYearsAsINDEX(obj)
  if(missing(MARGIN))
    return(tapply(obj$Data, FUN=mean, INDEX=yr, na.rm = TRUE))
  else
    return(apply(obj$Data, MARGIN=MARGIN, FUN=index.mean, INDEX=yr))
}

margin.dim <- function(obj, dims){
  grep(dims, attr(obj$Data, "dimensions"))
}

bubbleValidation <- function(mm.obj, obs, select.year, score=T, size.as.probability=T) {
  # Transform both data to the same grid (model grid)
  obs <- interpGridData(obs, new.grid = getGrid(mm.obj), method = "nearest")  
  
  x.mm <- mm.obj$xyCoords$x
  y.mm <- mm.obj$xyCoords$y
  arr <- mm.obj$Data
  arr.obs <- obs$Data
  yrs <- getYearsAsINDEX(mm.obj)
  yy <- unique(yrs)
  iyear <- which(yy[1]:yy[length(yy)]==select.year)
  lon.dim <- margin.dim(mm.obj,'lon')
  lat.dim <- margin.dim(mm.obj,'lat')
  member.dim <- margin.dim(mm.obj,'member')
  time.dim <- margin.dim(mm.obj,'time')
  n.mem <- dim(arr)[1]
  
  # Computation of terciles and exceedance probabilities
  # yearmean changes the data dimension. time.dim is in the first dimension!!
  y.mean <- yearmean(mm.obj, MARGIN=c(lat.dim,lon.dim,member.dim))
  terciles <- apply(y.mean, MARGIN=c(2,3,4), FUN=quantile, c(1/3,2/3), na.rm = TRUE)
  # Compute the probability for each tercile
  t.u <- array(data = NaN, dim = dim(y.mean)[1:3])
  t.l <- array(data = NaN, dim = dim(y.mean)[1:3])
  t.m <- array(data = NaN, dim = dim(y.mean)[1:3])
  prob <- array(data = NaN, dim = c(3,dim(y.mean)[1:3]))
  for (i in seq(1,dim(y.mean)[1])) {
      t.u[i,,] <- apply(y.mean[i,,,] > terciles[2,,,], MARGIN=c(1,2), FUN=sum, na.rm = TRUE)/n.mem
      t.l[i,,] <- apply(y.mean[i,,,] < terciles[1,,,], MARGIN=c(1,2), FUN=sum, na.rm = TRUE)/n.mem
      t.m[i,,] <- 1-t.u[i,,]-t.l[i,,]
      prob[1,i,,] <- t.l[i,,]
      prob[2,i,,] <- t.m[i,,]
      prob[3,i,,] <- t.u[i,,]
  }
  # Maximum probability from the terciles
  max.prob <- apply(prob, MARGIN=c(2,3,4), FUN=max)
  # Tercile for the maximum probability from the terciles
  t.max.prob <- apply(prob, MARGIN=c(2,3,4), FUN=which.max)

  #
  # Terciles for the observations
  #
  obs.y.mean <- apply(arr.obs, MARGIN=c(2,3), FUN=index.mean, INDEX=yrs)
  obs.terciles <- apply(obs.y.mean, MARGIN=c(2,3), FUN=quantile, c(1/3,2/3), na.rm=TRUE)    
  obs.t.u <- array(data = NaN, dim = dim(obs.y.mean))
  obs.t.l <- array(data = NaN, dim = dim(obs.y.mean))
  obs.t.m <- array(data = NaN, dim = dim(obs.y.mean))
  for (i in seq(1,dim(obs.y.mean)[1])) {
    obs.t.u[i,,] <- (obs.y.mean[i,,] > obs.terciles[2,,])
    obs.t.l[i,,] <- (obs.y.mean[i,,] < obs.terciles[1,,])
    obs.t.m[i,,] <- (obs.y.mean[i,,] >= obs.terciles[1,,] & obs.y.mean[i,,] <= obs.terciles[2,,])
  }
  obs.t <- obs.t.u*1+obs.t.l*-1 # 1 upper tercile, 0 middle tercile, -1 lower tercile
  
  #
  # Filter points with observations in model data 
  #
  # Select a year and eliminate de NaN cases detected for the observations. 
  v.max.prob <- as.vector(max.prob[iyear,,])
  v.t.max.prob <- as.vector(t.max.prob[iyear,,])
  v.nans <- complete.cases(as.vector(obs.t[iyear,,]))
  ve.max.prob <- v.max.prob[v.nans]
  if (!size.as.probability){
    ve.max.prob <- rep(0.5, length(ve.max.prob))
  }
  df <- data.frame(max.prob=ve.max.prob, t.max.prob=v.t.max.prob[v.nans])
  df$color <- "black"
  df$color[df$t.max.prob==3] <- "red"
  df$color[df$t.max.prob==2] <- "gold"
  df$color[df$t.max.prob==1] <- "blue"
  yx <- as.matrix(expand.grid(y.mm,x.mm))
  nn.yx <- yx[v.nans,]
  
  if (score) {
    #
    # Compute score (ROCSS)
    #
    v.score <- c()
    count <- 1
    for (ilon in seq(1,length(x.mm))) {
      for (ilat in seq(1,length(y.mm))) {
        n.nan <- sum(is.na(obs.t[,ilat,ilon]))
        if (n.nan == 0){
          # Compute the score only for the tercile with maximum probability
          select.tercile <- t.max.prob[iyear,ilat,ilon] 
          if (select.tercile == 1){
            res <- suppressWarnings(roc.area(obs.t.l[,ilat,ilon], t.l[,ilat,ilon]))
            v.score[count] <- res$A*2-1
          } 
          if (select.tercile == 2){
            res <- suppressWarnings(roc.area(obs.t.m[,ilat,ilon], t.m[,ilat,ilon]))
            v.score[count] <- res$A*2-1
          }
          if (select.tercile == 3){
            res <- suppressWarnings(roc.area(obs.t.u[,ilat,ilon], t.u[,ilat,ilon]))
            v.score[count] <- res$A*2-1
          }      
          count <- count+1
        }
      }  
    }
    # Select positive score values from negative values
    pos.val <- v.score>=0
    neg.val <- v.score<0
  }
  
  # Bubble plot
  par(bg="white", mar=c(3,3,1,5))
  if (score) {
    plot(nn.yx[pos.val,2], nn.yx[pos.val,1], cex=df$max.prob[pos.val]*3,
         col=alpha(df$color[pos.val], v.score[pos.val]), pch=19, xlab="", ylab="")
    points(nn.yx[neg.val,2], nn.yx[neg.val,1], pch=4, cex=0.75)
  } else {
    plot(nn.yx[,2], nn.yx[,1], cex=df$max.prob*3, col=df$color, pch=19, xlab="", ylab="")
  }
  map("world", ylim=range(y.mm), xlim=range(x.mm), col="black", lwd=1, interior=FALSE, add=TRUE)
  par(fig = c(0, 1, 0, 1), oma = c(0, 0, 0, 0), mar = c(0, 0, 0, 0), new = TRUE)
  plot(0, 0, type = "n", bty = "n", xaxt = "n", yaxt = "n")
  if (score){
    legend('right', c("T1","T2","T3","Negat.\nScore"), pch=c(19,19,19,4), col=c("blue","gold","red","black"),
           inset=c(0,0),xpd=T,bty="n")
  } else{
    legend('right', c("T1","T2","T3"), pch=c(19,19,19), col=c("blue","gold","red"), inset=c(0,0),xpd=T,bty="n")
  }
}
```

The bubbleValidation can be invoked with different levels of complexity:

```{r fig.width=5, fig.height=3, warning=FALSE, message=FALSE}
bubbleValidation(prd, obs, year.target, size.as.probability=F, score=F)
bubbleValidation(prd, obs, year.target, size.as.probability=T, score=F)
bubbleValidation(prd, obs, year.target, size.as.probability=T, score=T)
```